import google.generativeai as genai
import os
import time
import json
from datetime import datetime
from llm_memories_manager import ActivateLocalMemories, ShortContextManager, WriteNewLocalMemories
from image_generator import ImageGenerator

# Import c√°c module m·ªõi
from monitoring.performance_monitor import get_performance_monitor, measure_response_time
from monitoring.error_handler import get_error_handler, log_errors, ErrorSeverity
from security.security_manager import get_security_manager, security_check
from analytics.analytics_engine import get_analytics_engine
from utils.cache_manager import get_response_cache, get_image_cache
from utils.notification_system import get_notification_system, notify_info, notify_warning, notify_error
from config.config_manager import get_config_manager


class InstaBot:
    def __init__(self, api_key=None):
        """
        Kh·ªüi t·∫°o InstaBot v·ªõi Gemini AI, Memory Management System v√† Image Generator
        """
        # Kh·ªüi t·∫°o config manager
        self.config_manager = get_config_manager()
        
        # Kh·ªüi t·∫°o monitoring
        self.performance_monitor = get_performance_monitor()
        self.error_handler = get_error_handler()
        
        # Kh·ªüi t·∫°o security
        self.security_manager = get_security_manager()
        
        # Kh·ªüi t·∫°o analytics
        self.analytics_engine = get_analytics_engine()
        
        # Kh·ªüi t·∫°o cache
        self.response_cache = get_response_cache()
        self.image_cache = get_image_cache()
        
        # Kh·ªüi t·∫°o notification
        self.notification_system = get_notification_system()
        
        # B·∫Øt ƒë·∫ßu monitoring
        self.performance_monitor.start_monitoring()
        notify_info("InstaBot kh·ªüi t·∫°o th√†nh c√¥ng", "startup")
        
        if api_key:
            genai.configure(api_key=api_key)
        else:
            # ƒê·ªçc t·ª´ environment variable ho·∫∑c config
            api_key = os.getenv('GEMINI_API_KEY') or self.config_manager.get('ai', 'api_key')
            if not api_key:
                raise ValueError("C·∫ßn GEMINI_API_KEY trong environment ho·∫∑c truy·ªÅn api_key parameter")
            genai.configure(api_key=api_key)
        
        # Kh·ªüi t·∫°o model v·ªõi config
        model_name = self.config_manager.get('ai', 'model', 'gemini-2.5-flash-lite-preview-06-17')
        self.model = genai.GenerativeModel(model_name)
        
        # Kh·ªüi t·∫°o Image Generator
        try:
            self.image_generator = ImageGenerator(gemini_api_key=api_key)
            print("[CORE] ‚úÖ ImageGenerator ƒë√£ ƒë∆∞·ª£c t√≠ch h·ª£p")
        except Exception as e:
            print(f"[CORE] ‚ö†Ô∏è ImageGenerator init failed: {str(e)}")
            self.image_generator = None
        
        # Kh·ªüi t·∫°o Memory Management System v·ªõi config
        memory_config = self.config_manager.get('ai', 'memory_settings', {})
        self.local_memories = ActivateLocalMemories(
            limit_mem_storage=memory_config.get('long_memory_limit', 12)
        )
        self.short_context = ShortContextManager(
            s="user: ", 
            t="bot: ", 
            max_limit_short_mem_contxt=memory_config.get('short_context_limit', 10)
        )
        self.memory_writer = WriteNewLocalMemories(
            max_mem_context_towrite=memory_config.get('memory_write_threshold', 16),
            s="user: ",
            t="bot: "
        )
        
        # Th·ªëng k√™
        self.stats = {
            'total_messages': 0,
            'start_time': datetime.now(),
            'last_message_time': None,
            'memories_activated': 0,
            'memories_written': 0,
            'images_generated': 0
        }
        
        # Image processing state
        self.is_generating_image = False
        self.last_image_request_time = 0
        
        print("[CORE] ‚úÖ InstaBot v·ªõi Memory System v√† ImageGenerator ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng")

    def safe_write_memory(self, user_message, ai_response):
        """Safe wrapper cho memory writer ƒë·ªÉ tr√°nh list index out of range"""
        try:
            self.memory_writer.write_newLocalMem(user_message, ai_response)
            return True
        except IndexError as e:
            print(f"[MEMORY] ‚ö†Ô∏è Index error trong memory writer: {str(e)}")
            # Reset context n·∫øu b·ªã l·ªói index
            try:
                self.memory_writer.CONTEXT = []
                self.memory_writer.backup_contxt_writer()
                print("[MEMORY] üîÑ ƒê√£ reset memory writer context")
            except:
                pass
            return False
        except Exception as e:
            print(f"[MEMORY] ‚ö†Ô∏è L·ªói kh√°c trong memory writer: {str(e)}")
            return False

    def get_system_prompt(self):
        """
        prompt ƒë·ªÉ bot c√≥ th·ªÉ ph·∫£n h·ªìi theo √Ω c·ªßa b·∫°n 
        """
        return """nh·∫≠p prompt c·ªßa b·∫°n ·ªü ƒë√¢y."""

    @measure_response_time
    @log_errors(severity=ErrorSeverity.HIGH, context="generate_response")
    def generate_response(self, user_message, username="user"):
        """
        T·∫°o ph·∫£n h·ªìi v·ªõi Memory System, Context Analysis v√† Image Generation
        """
        try:
            # SECURITY: Validate message tr∆∞·ªõc khi x·ª≠ l√Ω
            is_valid, error_msg = self.security_manager.validate_message(user_message, username)
            if not is_valid:
                notify_warning(f"Message rejected: {error_msg}", "security")
                return "tin nh·∫Øn kh√¥ng h·ª£p l·ªá, vui l√≤ng th·ª≠ l·∫°i"
            
            # CACHE: Ki·ªÉm tra cached response
            cached_response = self.response_cache.get_cached_response(user_message, username)
            if cached_response:
                notify_info("S·ª≠ d·ª•ng cached response", "cache")
                return cached_response
            
            # C·∫≠p nh·∫≠t stats
            self.stats['total_messages'] += 1
            self.stats['last_message_time'] = datetime.now()
            
            # PRIORITY 1: Ki·ªÉm tra xem c√≥ ƒëang t·∫°o ·∫£nh kh√¥ng
            current_time = time.time()
            if self.is_generating_image:
                if current_time - self.last_image_request_time < 30:  # 30 gi√¢y timeout
                    return "ƒëang t·∫°o ·∫£nh n√®, ch·ªù t√≠ :vv"
                else:
                    # Reset state n·∫øu qu√° l√¢u
                    self.is_generating_image = False
                    notify_warning("Reset image generation state due to timeout", "image_generation")
            
            # PRIORITY 2: Ki·ªÉm tra c√≥ ph·∫£i image request kh√¥ng
            if self.image_generator and self.image_generator.is_image_request(user_message):
                return self.handle_image_request(user_message, username)
            
            # PRIORITY 3: X·ª≠ l√Ω tin nh·∫Øn th∆∞·ªùng v·ªõi memory system
            response = self.handle_normal_message(user_message, username)
            
            # CACHE: L∆∞u response v√†o cache
            self.response_cache.cache_response(user_message, response, username)
            
            # ANALYTICS: Ghi l·∫°i conversation
            response_time = time.time() - current_time
            self.analytics_engine.record_conversation(user_message, response, username, response_time)
            
            return response
            
        except Exception as e:
            self.error_handler.log_error(e, "generate_response", ErrorSeverity.HIGH, user_message)
            notify_error(f"L·ªói khi t·∫°o ph·∫£n h·ªìi: {str(e)}", "generate_response")
            
            # Fallback ph√π h·ª£p v·ªõi context
            fallback_responses = [
                "uh lag qu√°",
                "m√¨nh kh√¥ng hi·ªÉu", 
                "h·∫£",
                "·ªù",
                "sao z·∫°",
                "sorry m√¨nh lag"
            ]
            import random
            return random.choice(fallback_responses)

    def handle_image_request(self, user_message, username="user"):
        """
        X·ª≠ l√Ω y√™u c·∫ßu t·∫°o ·∫£nh
        """
        try:
            print(f"[CORE] üé® Ph√°t hi·ªán y√™u c·∫ßu t·∫°o ·∫£nh t·ª´ {username}")
            
            # Set image generation state
            self.is_generating_image = True
            self.last_image_request_time = time.time()
            
            # Extract description
            description = self.image_generator.extract_description(user_message)
            
            # T·∫°o response ngay ƒë·ªÉ user bi·∫øt ƒëang process
            processing_responses = [
                f"okee {username}, ƒëang t·∫°o ·∫£nh cho b·∫°n n√® :))",
                f"roger {username}, tui ƒëang v·∫Ω ·∫£nh :vv",
                f"ƒëang process ·∫£nh cho {username}, ch·ªù t√≠ nha :))",
                f"okk ƒëang t·∫°o ·∫£nh ngay {username} :D"
            ]
            import random
            initial_response = random.choice(processing_responses)
            
            # L∆∞u v√†o memory (ch·ªâ initial response)
            try:
                self.short_context.save_to_shortContextMem(user_message, initial_response)
                if self.safe_write_memory(user_message, initial_response):
                    self.stats['memories_written'] += 1
            except Exception as e:
                print(f"[MEMORY] ‚ö†Ô∏è L·ªói khi l∆∞u memory cho image request: {str(e)}")
            
            # Stats
            self.stats['images_generated'] += 1
            
            return initial_response
            
        except Exception as e:
            print(f"[CORE] ‚ùå L·ªói khi x·ª≠ l√Ω image request: {str(e)}")
            self.is_generating_image = False
            return f"sorry {username}, c√≥ l·ªói khi t·∫°o ·∫£nh :(("

    def handle_normal_message(self, user_message, username="user"):
        """
        X·ª≠ l√Ω tin nh·∫Øn th∆∞·ªùng v·ªõi memory system
        """
        # 1. K√≠ch ho·∫°t Local Memories d·ª±a tr√™n similarity - v·ªõi error handling
        long_term_memories = None
        try:
            long_term_memories = self.local_memories.activate_localMemories(user_message)
            if long_term_memories and len(long_term_memories) > 0:
                self.stats['memories_activated'] += 1
                print(f"[MEMORY] üß† K√≠ch ho·∫°t {len(long_term_memories)} k√Ω ·ª©c li√™n quan")
        except Exception as e:
            print(f"[MEMORY] ‚ö†Ô∏è L·ªói khi load k√Ω ·ª©c: {str(e)}")
            long_term_memories = None
        
        # 2. L·∫•y Short Context (ng·ªØ c·∫£nh ng·∫Øn h·∫°n) - v·ªõi error handling
        short_context = None
        try:
            short_context = self.short_context.activate_shortContetxMem()
            if short_context and str(short_context) == "[]":
                short_context = None
        except Exception as e:
            print(f"[MEMORY] ‚ö†Ô∏è L·ªói khi load context: {str(e)}")
            short_context = None
        
        # 3. X√¢y d·ª±ng prompt v·ªõi nhi·ªÅu lu·ªìng d·ªØ li·ªáu - safe approach
        memory_context = ""
        if long_term_memories and len(long_term_memories) > 0:
            memory_context += "\nk√Ω ·ª©c t·ª´ tr∆∞·ªõc:\n"
            # Safe slicing ƒë·ªÉ tr√°nh l·ªói index
            safe_memories = long_term_memories[:min(3, len(long_term_memories))]
            for memory in safe_memories:
                if memory and memory.strip():
                    memory_context += f"- {memory}\n"
        
        conversation_context = ""
        if short_context and len(short_context) > 0:
            conversation_context += "\ncu·ªôc tr√≤ chuy·ªán g·∫ßn ƒë√¢y:\n"
            # Safe slicing ƒë·ªÉ tr√°nh l·ªói index
            safe_context = short_context[-min(6, len(short_context)):]
            for context in safe_context:
                if context and context.strip():
                    conversation_context += f"{context}\n"
        
        # 4. T·∫°o prompt ho√†n ch·ªânh ng·∫Øn g·ªçn
        full_prompt = f"""{self.get_system_prompt()}
{memory_context}
{conversation_context}
tin nh·∫Øn: {user_message}

tr·∫£ l·ªùi:"""

        print(f"[CORE] ü§î ƒêang ph√¢n t√≠ch tin nh·∫Øn: '{user_message[:30]}...'")
        
        # 5. G·ªçi Gemini AI v·ªõi config t·ª´ config manager
        generation_config = {
            'temperature': self.config_manager.get('ai', 'temperature', 0.7),
            'top_p': self.config_manager.get('ai', 'top_p', 0.8),
            'top_k': self.config_manager.get('ai', 'top_k', 70),
            'max_output_tokens': self.config_manager.get('ai', 'max_tokens', 1024),
        }
        
        response = self.model.generate_content(
            full_prompt,
            generation_config=generation_config
        )
        ai_response = response.text.strip()
        
        # 6. Post-processing ƒë·ªÉ ƒë·∫£m b·∫£o ng·∫Øn g·ªçn v√† t·ª± nhi√™n
        ai_response = self.post_process_response(ai_response)
        
        # 7. Ki·ªÉm tra ƒë·ªô d√†i - n·∫øu qu√° d√†i th√¨ c·∫Øt
        words = ai_response.split()
        if len(words) > 25:  # N·∫øu qu√° 25 t·ª´
            ai_response = ' '.join(words[:20]) + "..."
        
        # 8. L∆∞u v√†o Memory Systems - v·ªõi safe error handling
        try:
            # L∆∞u v√†o short context
            self.short_context.save_to_shortContextMem(user_message, ai_response)
            
            # L∆∞u v√†o long term memory v·ªõi safe wrapper
            if self.safe_write_memory(user_message, ai_response):
                self.stats['memories_written'] += 1
                print(f"[MEMORY] üíæ ƒê√£ l∆∞u v√†o memory systems")
            else:
                print(f"[MEMORY] ‚ö†Ô∏è L∆∞u memory th·∫•t b·∫°i nh∆∞ng bot v·∫´n ho·∫°t ƒë·ªông")
                
        except Exception as e:
            print(f"[MEMORY] ‚ö†Ô∏è L·ªói khi l∆∞u short context: {str(e)}")
        
        print(f"[CORE] ‚úÖ Ph·∫£n h·ªìi: '{ai_response}'")
        
        return ai_response

    def process_image_generation(self, description, username="user"):
        """
        X·ª≠ l√Ω t·∫°o ·∫£nh trong background (c√≥ th·ªÉ d√πng threading)
        Tr·∫£ v·ªÅ result ƒë·ªÉ main app g·ª≠i ·∫£nh
        """
        try:
            print(f"[CORE] üé® B·∫Øt ƒë·∫ßu t·∫°o ·∫£nh: '{description}'")
            
            # Generate image
            result = self.image_generator.generate_image(description)
            
            # Reset state
            self.is_generating_image = False
            
            # Return result v·ªõi response text
            if result['success']:
                result['response_text'] = self.image_generator.get_image_response_text(result, username)
                print(f"[CORE] ‚úÖ T·∫°o ·∫£nh th√†nh c√¥ng cho {username}")
            else:
                result['response_text'] = self.image_generator.get_image_response_text(result, username)
                print(f"[CORE] ‚ùå T·∫°o ·∫£nh th·∫•t b·∫°i cho {username}")
            
            return result
            
        except Exception as e:
            print(f"[CORE] ‚ùå L·ªói critical trong image generation: {str(e)}")
            self.is_generating_image = False
            return {
                'success': False,
                'error': str(e),
                'response_text': f"sorry {username}, c√≥ l·ªói nghi√™m tr·ªçng khi t·∫°o ·∫£nh :(("
            }

    def post_process_response(self, response):
        """
        Ch·ªâ x·ª≠ l√Ω c∆° b·∫£n - lo·∫°i b·ªè emoji v√† lowercase
        """
        import re
        
        # Ch·ªâ lo·∫°i b·ªè emoji v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
        cleaned_text = re.sub(r'[^\w\s\.\!\?\,\-\'\"]', '', response)
        cleaned_text = ''.join(char for char in cleaned_text if ord(char) < 127 or char.isalpha())
        
        # Chuy·ªÉn v·ªÅ lowercase
        cleaned_text = cleaned_text.lower()
        
        return cleaned_text.strip()

    def get_memory_stats(self):
        """
        L·∫•y th·ªëng k√™ v·ªÅ memory system v√† image generation
        """
        memories_count = 0
        memories_dir = "./memories"
        if os.path.exists(memories_dir):
            memories_count = len([f for f in os.listdir(memories_dir) if f.endswith('.txt')])
        
        # Image stats
        image_stats = {}
        if self.image_generator:
            image_stats = self.image_generator.get_stats()
        
        # Performance stats
        performance_stats = self.performance_monitor.get_current_stats()
        
        # Security stats
        security_stats = self.security_manager.get_security_stats()
        
        # Analytics stats
        analytics_stats = self.analytics_engine.get_conversation_trends(7)
        
        return {
            'total_messages': self.stats['total_messages'],
            'memories_activated': self.stats['memories_activated'],
            'memories_written': self.stats['memories_written'],
            'images_generated': self.stats['images_generated'],
            'total_memory_files': memories_count,
            'short_context_length': len(self.short_context.context) if self.short_context.context else 0,
            'uptime_minutes': (datetime.now() - self.stats['start_time']).total_seconds() / 60,
            'image_generation_stats': image_stats,
            'is_generating_image': self.is_generating_image,
            'performance_stats': performance_stats,
            'security_stats': security_stats,
            'analytics_stats': analytics_stats
        }

    def analyze_conversation_flow(self):
        """
        Ph√¢n t√≠ch lu·ªìng cu·ªôc tr√≤ chuy·ªán cho c√°i nh√¨n tr·ª±c quan
        """
        short_context = self.short_context.activate_shortContetxMem()
        if not short_context:
            return "Ch∆∞a c√≥ cu·ªôc tr√≤ chuy·ªán n√†o"
        
        analysis = {
            'conversation_length': len(short_context),
            'user_messages': [msg for msg in short_context if msg.startswith('user:')],
            'bot_responses': [msg for msg in short_context if msg.startswith('bot:')],
            'topics_flow': []
        }
        
        # Ph√¢n t√≠ch ch·ªß ƒë·ªÅ
        for msg in analysis['user_messages']:
            clean_msg = msg.replace('user:', '').strip()
            if len(clean_msg.split()) > 2:
                analysis['topics_flow'].append(clean_msg[:30] + "...")
        
        return analysis

    def clear_short_memory(self):
        """
        X√≥a memory ng·∫Øn h·∫°n
        """
        self.short_context.context = []
        self.short_context.backup_short_context_writer()
        print("[MEMORY] üóëÔ∏è ƒê√£ x√≥a ng·ªØ c·∫£nh ng·∫Øn h·∫°n")

    def get_related_memories(self, query):
        """
        T√¨m k√Ω ·ª©c li√™n quan ƒë·∫øn query
        """
        return self.local_memories.activate_localMemories(query)


# Factory function
def create_insta_bot(api_key=None):
    """
    T·∫°o InstaBot instance v·ªõi Memory Management
    """
    try:
        bot = InstaBot(api_key=api_key)
        notify_info("InstaBot instance created successfully", "factory")
        return bot
    except Exception as e:
        notify_error(f"Failed to create InstaBot: {str(e)}", "factory")
        raise

def cleanup_insta_bot(bot):
    """
    Cleanup function ƒë·ªÉ d·ªçn d·∫πp InstaBot
    """
    try:
        if hasattr(bot, 'performance_monitor'):
            bot.performance_monitor.stop_monitoring()
            bot.performance_monitor.save_report()
        
        if hasattr(bot, 'analytics_engine'):
            bot.analytics_engine.save_data()
            bot.analytics_engine.save_report()
        
        if hasattr(bot, 'security_manager'):
            bot.security_manager.save_security_report()
        
        if hasattr(bot, 'notification_system'):
            bot.notification_system.stop()
        
        notify_info("InstaBot cleanup completed", "cleanup")
        
    except Exception as e:
        notify_error(f"Error during cleanup: {str(e)}", "cleanup")


# Test function v·ªõi memory analysis
def test_bot():
    """
    Test bot v·ªõi memory system
    """
    print("[TEST] üß™ Testing InstaBot v·ªõi Memory System...")
    
    try:
        bot = create_insta_bot()
        
        test_messages = [
            "hi t√¥i t√™n t√¢n",
            "t√¥i ·ªü h√† n·ªôi", 
            "b·∫°n c√≥ nh·ªõ t√™n t√¥i kh√¥ng?",
            "t√¥i ·ªü ƒë√¢u nh·ªâ?"
        ]
        
        for i, msg in enumerate(test_messages):
            print(f"\n[TEST] Round {i+1}")
            print(f"User: {msg}")
            response = bot.generate_response(msg, "testuser")
            print(f"Bot: {response}")
            
            # Hi·ªÉn th·ªã memory stats
            if i > 0:
                stats = bot.get_memory_stats()
                print(f"Memory Stats: {stats}")
            
            time.sleep(1)
        
        # Ph√¢n t√≠ch conversation flow
        print(f"\n[ANALYSIS] üìä Conversation Flow:")
        flow = bot.analyze_conversation_flow()
        print(flow)
        
    except Exception as e:
        print(f"[TEST] ‚ùå C·∫ßn GEMINI_API_KEY ƒë·ªÉ test: {str(e)}")


if __name__ == "__main__":
    test_bot() 