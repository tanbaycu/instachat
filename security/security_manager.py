import time
import hashlib
import json
import os
from datetime import datetime, timedelta
from collections import defaultdict, deque
import re


class SecurityManager:
    def __init__(self, config_file="security/security_config.json"):
        self.config_file = config_file
        self.message_history = deque(maxlen=1000)
        self.rate_limits = defaultdict(list)
        self.spam_scores = defaultdict(float)
        self.blocked_users = set()
        self.suspicious_patterns = []
        
        # Load config
        self.config = self.load_config()
        
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        os.makedirs(os.path.dirname(config_file), exist_ok=True)
        
        print("[SECURITY] ğŸ” Security Manager Ä‘Ã£ khá»Ÿi táº¡o")

    def load_config(self):
        """Load security configuration"""
        default_config = {
            "rate_limits": {
                "messages_per_minute": 30,
                "messages_per_hour": 200,
                "ai_requests_per_minute": 10,
                "image_requests_per_hour": 20
            },
            "spam_detection": {
                "max_duplicate_messages": 3,
                "max_similar_messages": 5,
                "spam_keywords": ["spam", "bot", "fake", "scam", "hack"],
                "suspicious_patterns": [
                    r"\b(click|visit|go to)\s+https?://",
                    r"\b(free|win|prize|money)\b.*\b(click|visit|link)\b",
                    r"\b(urgent|limited time|act now)\b"
                ]
            },
            "account_protection": {
                "max_login_attempts": 3,
                "cooldown_minutes": 30,
                "suspicious_activity_threshold": 10
            },
            "content_filter": {
                "blocked_keywords": ["hate", "violence", "illegal"],
                "max_message_length": 1000,
                "allow_links": False
            }
        }
        
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                # Merge vá»›i default config
                return {**default_config, **config}
            else:
                # Táº¡o file config máº·c Ä‘á»‹nh
                with open(self.config_file, 'w', encoding='utf-8') as f:
                    json.dump(default_config, f, indent=2, ensure_ascii=False)
                return default_config
        except Exception as e:
            print(f"[SECURITY] âš ï¸ Lá»—i load config: {str(e)}")
            return default_config

    def check_rate_limit(self, user_id, action_type="message"):
        """Kiá»ƒm tra rate limit cho user"""
        current_time = time.time()
        
        # Láº¥y rate limit config
        if action_type == "message":
            per_minute = self.config["rate_limits"]["messages_per_minute"]
            per_hour = self.config["rate_limits"]["messages_per_hour"]
        elif action_type == "ai_request":
            per_minute = self.config["rate_limits"]["ai_requests_per_minute"]
            per_hour = self.config["rate_limits"]["ai_requests_per_minute"] * 6  # Approximate
        elif action_type == "image_request":
            per_minute = 2  # Stricter for images
            per_hour = self.config["rate_limits"]["image_requests_per_hour"]
        else:
            per_minute = 10
            per_hour = 100
        
        # Dá»n dáº¹p old entries
        user_actions = self.rate_limits[user_id]
        cutoff_time = current_time - 3600  # 1 hour ago
        self.rate_limits[user_id] = [t for t in user_actions if t > cutoff_time]
        
        # Kiá»ƒm tra limits
        recent_actions = [t for t in self.rate_limits[user_id] if t > current_time - 60]  # Last minute
        hourly_actions = self.rate_limits[user_id]  # Last hour
        
        if len(recent_actions) >= per_minute:
            print(f"[SECURITY] ğŸš« Rate limit exceeded (per minute): {user_id}")
            return False, f"QuÃ¡ nhiá»u {action_type} trong 1 phÃºt. Vui lÃ²ng chá»."
        
        if len(hourly_actions) >= per_hour:
            print(f"[SECURITY] ğŸš« Rate limit exceeded (per hour): {user_id}")
            return False, f"QuÃ¡ nhiá»u {action_type} trong 1 giá». Vui lÃ²ng chá»."
        
        # ThÃªm action hiá»‡n táº¡i
        self.rate_limits[user_id].append(current_time)
        return True, ""

    def detect_spam(self, message, user_id):
        """PhÃ¡t hiá»‡n spam trong tin nháº¯n"""
        spam_score = 0
        reasons = []
        
        # 1. Kiá»ƒm tra duplicate messages
        user_messages = [msg for msg in self.message_history if msg.get('user_id') == user_id]
        recent_messages = [msg['content'] for msg in user_messages[-10:]]  # 10 tin nháº¯n gáº§n nháº¥t
        
        duplicate_count = recent_messages.count(message)
        if duplicate_count > self.config["spam_detection"]["max_duplicate_messages"]:
            spam_score += 30
            reasons.append("Tin nháº¯n trÃ¹ng láº·p")
        
        # 2. Kiá»ƒm tra similar messages
        similar_count = sum(1 for msg in recent_messages if self.similarity(message, msg) > 0.8)
        if similar_count > self.config["spam_detection"]["max_similar_messages"]:
            spam_score += 20
            reasons.append("Tin nháº¯n tÆ°Æ¡ng tá»±")
        
        # 3. Kiá»ƒm tra spam keywords
        spam_keywords = self.config["spam_detection"]["spam_keywords"]
        keyword_matches = sum(1 for keyword in spam_keywords if keyword.lower() in message.lower())
        if keyword_matches > 0:
            spam_score += keyword_matches * 10
            reasons.append("Chá»©a tá»« khÃ³a spam")
        
        # 4. Kiá»ƒm tra suspicious patterns
        pattern_matches = 0
        for pattern in self.config["spam_detection"]["suspicious_patterns"]:
            if re.search(pattern, message, re.IGNORECASE):
                pattern_matches += 1
        
        if pattern_matches > 0:
            spam_score += pattern_matches * 15
            reasons.append("Pattern Ä‘Ã¡ng nghi")
        
        # 5. Kiá»ƒm tra message length vÃ  structure
        if len(message) > self.config["content_filter"]["max_message_length"]:
            spam_score += 10
            reasons.append("Tin nháº¯n quÃ¡ dÃ i")
        
        # 6. Kiá»ƒm tra links náº¿u khÃ´ng Ä‘Æ°á»£c phÃ©p
        if not self.config["content_filter"]["allow_links"]:
            if re.search(r'https?://', message):
                spam_score += 25
                reasons.append("Chá»©a link")
        
        # 7. Kiá»ƒm tra CAPS LOCK
        if len(message) > 20 and message.isupper():
            spam_score += 15
            reasons.append("ToÃ n chá»¯ hoa")
        
        # Cáº­p nháº­t spam score cho user
        self.spam_scores[user_id] = (self.spam_scores[user_id] * 0.9) + (spam_score * 0.1)
        
        is_spam = spam_score > 50 or self.spam_scores[user_id] > 30
        
        if is_spam:
            print(f"[SECURITY] ğŸš¨ Spam detected from {user_id}: {reasons}")
        
        return is_spam, spam_score, reasons

    def similarity(self, text1, text2):
        """TÃ­nh similarity giá»¯a 2 text"""
        if not text1 or not text2:
            return 0
        
        # Simple similarity based on common words
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0

    def check_content_filter(self, message):
        """Kiá»ƒm tra content filter"""
        blocked_keywords = self.config["content_filter"]["blocked_keywords"]
        
        for keyword in blocked_keywords:
            if keyword.lower() in message.lower():
                print(f"[SECURITY] ğŸš« Blocked keyword detected: {keyword}")
                return False, f"Tin nháº¯n chá»©a ná»™i dung khÃ´ng Ä‘Æ°á»£c phÃ©p"
        
        return True, ""

    def log_message(self, message, user_id, response="", action_taken=""):
        """Ghi láº¡i tin nháº¯n vÃ o history"""
        message_data = {
            'timestamp': datetime.now().isoformat(),
            'user_id': user_id,
            'content': message,
            'response': response,
            'action_taken': action_taken,
            'spam_score': self.spam_scores.get(user_id, 0)
        }
        
        self.message_history.append(message_data)

    def is_user_blocked(self, user_id):
        """Kiá»ƒm tra user cÃ³ bá»‹ block khÃ´ng"""
        return user_id in self.blocked_users

    def block_user(self, user_id, reason=""):
        """Block user"""
        self.blocked_users.add(user_id)
        print(f"[SECURITY] ğŸš« User blocked: {user_id} - {reason}")

    def unblock_user(self, user_id):
        """Unblock user"""
        self.blocked_users.discard(user_id)
        print(f"[SECURITY] âœ… User unblocked: {user_id}")

    def validate_message(self, message, user_id):
        """Validation tá»•ng há»£p cho tin nháº¯n"""
        # Kiá»ƒm tra user cÃ³ bá»‹ block khÃ´ng
        if self.is_user_blocked(user_id):
            return False, "User Ä‘Ã£ bá»‹ block"
        
        # Kiá»ƒm tra rate limit
        rate_ok, rate_msg = self.check_rate_limit(user_id, "message")
        if not rate_ok:
            return False, rate_msg
        
        # Kiá»ƒm tra content filter
        content_ok, content_msg = self.check_content_filter(message)
        if not content_ok:
            return False, content_msg
        
        # Kiá»ƒm tra spam
        is_spam, spam_score, reasons = self.detect_spam(message, user_id)
        if is_spam:
            # Auto-block náº¿u spam score quÃ¡ cao
            if spam_score > 80:
                self.block_user(user_id, f"Spam score: {spam_score}")
                return False, "User Ä‘Ã£ bá»‹ block do spam"
            
            return False, f"Tin nháº¯n bá»‹ tá»« chá»‘i do spam (score: {spam_score})"
        
        return True, ""

    def get_security_stats(self):
        """Láº¥y thá»‘ng kÃª báº£o máº­t"""
        total_messages = len(self.message_history)
        spam_messages = sum(1 for msg in self.message_history if msg.get('spam_score', 0) > 30)
        
        return {
            'total_messages': total_messages,
            'spam_messages': spam_messages,
            'blocked_users': len(self.blocked_users),
            'active_rate_limits': len(self.rate_limits),
            'spam_rate': (spam_messages / max(1, total_messages)) * 100,
            'avg_spam_score': sum(self.spam_scores.values()) / max(1, len(self.spam_scores))
        }

    def print_security_summary(self):
        """In tÃ³m táº¯t báº£o máº­t"""
        stats = self.get_security_stats()
        
        print(f"\n[SECURITY] ğŸ” === SECURITY SUMMARY ===")
        print(f"[SECURITY] ğŸ“Š Total Messages: {stats['total_messages']}")
        print(f"[SECURITY] ğŸš¨ Spam Messages: {stats['spam_messages']} ({stats['spam_rate']:.1f}%)")
        print(f"[SECURITY] ğŸš« Blocked Users: {stats['blocked_users']}")
        print(f"[SECURITY] â±ï¸ Active Rate Limits: {stats['active_rate_limits']}")
        print(f"[SECURITY] ğŸ“ˆ Avg Spam Score: {stats['avg_spam_score']:.1f}")
        
        if self.blocked_users:
            print(f"[SECURITY] ğŸš« Blocked Users List: {', '.join(list(self.blocked_users)[:5])}")
        
        print(f"[SECURITY] ===================================\n")

    def save_security_report(self, filename="security/security_report.json"):
        """LÆ°u bÃ¡o cÃ¡o báº£o máº­t"""
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'stats': self.get_security_stats(),
                'blocked_users': list(self.blocked_users),
                'recent_messages': list(self.message_history)[-50:],  # 50 tin nháº¯n gáº§n nháº¥t
                'config': self.config
            }
            
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"[SECURITY] ğŸ’¾ ÄÃ£ lÆ°u bÃ¡o cÃ¡o: {filename}")
            return True
            
        except Exception as e:
            print(f"[SECURITY] âŒ Lá»—i lÆ°u bÃ¡o cÃ¡o: {str(e)}")
            return False


# Singleton instance
_security_manager = None

def get_security_manager():
    """Láº¥y instance singleton cá»§a SecurityManager"""
    global _security_manager
    if _security_manager is None:
        _security_manager = SecurityManager()
    return _security_manager


# Decorator cho security check
def security_check(func):
    """Decorator Ä‘á»ƒ kiá»ƒm tra báº£o máº­t trÆ°á»›c khi xá»­ lÃ½ tin nháº¯n"""
    def wrapper(self, message, user_id="unknown", *args, **kwargs):
        security_manager = get_security_manager()
        
        # Validate message
        is_valid, error_msg = security_manager.validate_message(message, user_id)
        
        if not is_valid:
            print(f"[SECURITY] ğŸš« Message rejected: {error_msg}")
            return error_msg
        
        # Log message
        try:
            result = func(self, message, user_id, *args, **kwargs)
            security_manager.log_message(message, user_id, str(result)[:100], "processed")
            return result
        except Exception as e:
            security_manager.log_message(message, user_id, "", f"error: {str(e)}")
            raise e
    
    return wrapper


if __name__ == "__main__":
    # Test security manager
    security = get_security_manager()
    
    # Test normal message
    print("Test 1: Normal message")
    valid, msg = security.validate_message("Hello, how are you?", "user1")
    print(f"Valid: {valid}, Message: {msg}")
    
    # Test spam
    print("\nTest 2: Spam message")
    valid, msg = security.validate_message("FREE MONEY CLICK HERE NOW!!!", "user2")
    print(f"Valid: {valid}, Message: {msg}")
    
    # Test rate limit
    print("\nTest 3: Rate limit")
    for i in range(35):  # Exceed rate limit
        valid, msg = security.validate_message(f"Message {i}", "user3")
        if not valid:
            print(f"Rate limited at message {i}: {msg}")
            break
    
    security.print_security_summary()
    security.save_security_report() 